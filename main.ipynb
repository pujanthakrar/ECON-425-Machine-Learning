{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0      1      2     3      4     5      6\n",
      "0     vhigh  vhigh      2     2  small   low  unacc\n",
      "1     vhigh  vhigh      2     2  small   med  unacc\n",
      "2     vhigh  vhigh      2     2  small  high  unacc\n",
      "3     vhigh  vhigh      2     2    med   low  unacc\n",
      "4     vhigh  vhigh      2     2    med   med  unacc\n",
      "5     vhigh  vhigh      2     2    med  high  unacc\n",
      "6     vhigh  vhigh      2     2    big   low  unacc\n",
      "7     vhigh  vhigh      2     2    big   med  unacc\n",
      "8     vhigh  vhigh      2     2    big  high  unacc\n",
      "9     vhigh  vhigh      2     4  small   low  unacc\n",
      "10    vhigh  vhigh      2     4  small   med  unacc\n",
      "11    vhigh  vhigh      2     4  small  high  unacc\n",
      "12    vhigh  vhigh      2     4    med   low  unacc\n",
      "13    vhigh  vhigh      2     4    med   med  unacc\n",
      "14    vhigh  vhigh      2     4    med  high  unacc\n",
      "15    vhigh  vhigh      2     4    big   low  unacc\n",
      "16    vhigh  vhigh      2     4    big   med  unacc\n",
      "17    vhigh  vhigh      2     4    big  high  unacc\n",
      "18    vhigh  vhigh      2  more  small   low  unacc\n",
      "19    vhigh  vhigh      2  more  small   med  unacc\n",
      "20    vhigh  vhigh      2  more  small  high  unacc\n",
      "21    vhigh  vhigh      2  more    med   low  unacc\n",
      "22    vhigh  vhigh      2  more    med   med  unacc\n",
      "23    vhigh  vhigh      2  more    med  high  unacc\n",
      "24    vhigh  vhigh      2  more    big   low  unacc\n",
      "25    vhigh  vhigh      2  more    big   med  unacc\n",
      "26    vhigh  vhigh      2  more    big  high  unacc\n",
      "27    vhigh  vhigh      3     2  small   low  unacc\n",
      "28    vhigh  vhigh      3     2  small   med  unacc\n",
      "29    vhigh  vhigh      3     2  small  high  unacc\n",
      "...     ...    ...    ...   ...    ...   ...    ...\n",
      "1698    low    low      4  more    big   low  unacc\n",
      "1699    low    low      4  more    big   med   good\n",
      "1700    low    low      4  more    big  high  vgood\n",
      "1701    low    low  5more     2  small   low  unacc\n",
      "1702    low    low  5more     2  small   med  unacc\n",
      "1703    low    low  5more     2  small  high  unacc\n",
      "1704    low    low  5more     2    med   low  unacc\n",
      "1705    low    low  5more     2    med   med  unacc\n",
      "1706    low    low  5more     2    med  high  unacc\n",
      "1707    low    low  5more     2    big   low  unacc\n",
      "1708    low    low  5more     2    big   med  unacc\n",
      "1709    low    low  5more     2    big  high  unacc\n",
      "1710    low    low  5more     4  small   low  unacc\n",
      "1711    low    low  5more     4  small   med    acc\n",
      "1712    low    low  5more     4  small  high   good\n",
      "1713    low    low  5more     4    med   low  unacc\n",
      "1714    low    low  5more     4    med   med   good\n",
      "1715    low    low  5more     4    med  high  vgood\n",
      "1716    low    low  5more     4    big   low  unacc\n",
      "1717    low    low  5more     4    big   med   good\n",
      "1718    low    low  5more     4    big  high  vgood\n",
      "1719    low    low  5more  more  small   low  unacc\n",
      "1720    low    low  5more  more  small   med    acc\n",
      "1721    low    low  5more  more  small  high   good\n",
      "1722    low    low  5more  more    med   low  unacc\n",
      "1723    low    low  5more  more    med   med   good\n",
      "1724    low    low  5more  more    med  high  vgood\n",
      "1725    low    low  5more  more    big   low  unacc\n",
      "1726    low    low  5more  more    big   med   good\n",
      "1727    low    low  5more  more    big  high  vgood\n",
      "\n",
      "[1728 rows x 7 columns]\n",
      "[[3. 3. 0. ... 0. 0. 0.]\n",
      " [3. 3. 0. ... 0. 1. 0.]\n",
      " [3. 3. 0. ... 0. 2. 0.]\n",
      " ...\n",
      " [0. 0. 3. ... 2. 0. 0.]\n",
      " [0. 0. 3. ... 2. 1. 0.]\n",
      " [0. 0. 3. ... 2. 2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from util1 import Cost_Function, Gradient_Descent, Cost_Function_Derivative, Cost_Function, Prediction, Sigmoid\n",
    "from dataTrans import download_data,transtonumber,rescaleNormalization\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "#% step-1: load data and divide it into two subsets, used for training and testing\n",
    "data = download_data('car.csv',[0,1,2,3,4,5,6])\n",
    "colnames = ['buying','maint','doors','persons','lug_boot','safety','class']\n",
    "print(data)\n",
    "\n",
    "### define the transformation notation \n",
    "buying = ['low','med','high','vhigh']\n",
    "        # low = 0, med = 1, high = 2, vhigh = 3\n",
    "maint = ['low','med','high','vhigh']\n",
    "        # low = 0, med = 1, high = 2, vhigh = 3\n",
    "doors = ['2', '3', '4', '5more']\n",
    "        # 2 = 0, 3 = 1, 4 = 2, 5more = 3\n",
    "persons = ['2', '4', 'more']\n",
    "        # 2 = 0, 4 = 1, more = 2\n",
    "boot = ['small','med', 'big']\n",
    "        # samll = 0, med = 1, big = 2\n",
    "safety = ['low', 'med','high']\n",
    "        # low = 0, med = 1, high = 2\n",
    "names = [buying,maint,doors,persons,boot,safety]\n",
    "\n",
    "### transform\n",
    "car1 = np.transpose(np.zeros(np.shape(car)))\n",
    "for i in range(6):\n",
    "    car1[i] = transtonumber(car[i],names[i])\n",
    "# Nomoralization \n",
    "#X = np.transpose(rescaleNormalization(car1))\n",
    "X = np.transpose(car1)\n",
    "\n",
    "\n",
    "## transform Y to 0 & 1 \n",
    "y = np.zeros(np.shape(car[6]))\n",
    "for i in range(len(car[6])):\n",
    "    if data[6][i] != 'unacc':\n",
    "        y[i] = 1\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[[1. 1. 2. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 2. 2. 0.]\n",
      " [3. 1. 2. ... 2. 2. 0.]\n",
      " ...\n",
      " [3. 3. 2. ... 1. 2. 0.]\n",
      " [0. 0. 1. ... 2. 0. 0.]\n",
      " [1. 3. 1. ... 2. 2. 0.]]\n",
      "1157\n",
      "1157\n",
      "571\n",
      "571\n"
     ]
    }
   ],
   "source": [
    "# number of training samples\n",
    "\n",
    "\n",
    "trainX,testX,trainY,testY = train_test_split(X,y,test_size=0.33)\n",
    "\n",
    "# check properties of data\n",
    "print(testY)\n",
    "print(testX)\n",
    "print(len(trainX))\n",
    "print(len(trainY))\n",
    "print(len(testX))\n",
    "print(len(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score SK: 0.8651488616462347\n",
      "Avg Error SK: 0.13485113835376533\n",
      "Std Error SK: 0.34156450172472397\n",
      "SK Learn Confusion Matrix:\n",
      "[[373  35]\n",
      " [ 42 121]]\n",
      "accuracy: 0.8651488616462347\n",
      "precision: 0.7756410256410257\n",
      "recall: 0.7423312883435583\n"
     ]
    }
   ],
   "source": [
    "#SK learn method\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# call the function fit() to train the class instance\n",
    "clf.fit(trainX,trainY)\n",
    "# accuracy for sklearn\n",
    "scikit_score = clf.score(testX,testY)\n",
    "\n",
    "\n",
    "#prediction with sklearn\n",
    "predSK = clf.predict(testX)\n",
    "\n",
    "# evaluation\n",
    "testYDiff1 = np.abs(predSK - testY)\n",
    "avgErr1 = np.mean(testYDiff1)\n",
    "stdErr1 = np.std(testYDiff1)\n",
    "\n",
    "print(\"Score SK:\", scikit_score)\n",
    "print(\"Avg Error SK:\", avgErr1)\n",
    "print(\"Std Error SK:\", stdErr1)\n",
    "\n",
    "#confusion matrix\n",
    "print(\"SK Learn Confusion Matrix:\")\n",
    "print(confusion_matrix(testY,predSK))\n",
    "print(\"accuracy:\",accuracy_score(testY,predSK))\n",
    "print(\"precision:\",precision_score(testY,predSK))\n",
    "print(\"recall:\",recall_score(testY,predSK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score SVM: 0.8633975481611208\n",
      "Avg Error SVM: 0.13660245183887915\n",
      "Std Error SVM: 0.34342717130490114\n",
      "SVM Learn Confusion Matrix:\n",
      "[[373  35]\n",
      " [ 42 121]]\n",
      "accuracy: 0.8633975481611208\n",
      "precision: 0.7741935483870968\n",
      "recall: 0.7361963190184049\n"
     ]
    }
   ],
   "source": [
    "# fitting SVM model\n",
    "\n",
    "\n",
    "svm = svm.SVC(C = 1000, kernel = \"linear\")\n",
    "svm.fit(trainX, trainY)\n",
    "svm_score = svm.score(testX,testY)\n",
    "\n",
    "#prediction with svm\n",
    "predSVM = svm.predict(testX) \n",
    "\n",
    "# evaluation\n",
    "svmDiff = np.abs(predSVM - testY)\n",
    "svm_avgErr = np.mean(svmDiff)\n",
    "svm_stdErr = np.std(svmDiff)\n",
    "\n",
    "print(\"Score SVM:\", svm_score)\n",
    "print(\"Avg Error SVM:\", svm_avgErr)\n",
    "print(\"Std Error SVM:\", svm_stdErr)\n",
    "\n",
    "#confusion matrix\n",
    "print(\"SVM Learn Confusion Matrix:\")\n",
    "print(confusion_matrix(testY,predSK))\n",
    "print(\"accuracy:\",accuracy_score(testY,predSVM))\n",
    "print(\"precision:\",precision_score(testY,predSVM))\n",
    "print(\"recall:\",recall_score(testY,predSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score RF: 0.9824868651488616\n",
      "Avg Error RF: 0.017513134851138354\n",
      "Std Error RF: 0.1311732631248617\n",
      "RF Learn Confusion Matrix:\n",
      "[[403   5]\n",
      " [  5 158]]\n",
      "accuracy: 0.9824868651488616\n",
      "precision: 0.9693251533742331\n",
      "recall: 0.9693251533742331\n"
     ]
    }
   ],
   "source": [
    "# fitting random forest model\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=0)  \n",
    "rf.fit(trainX, trainY) \n",
    "rf_score = rf.score(testX,testY)\n",
    "\n",
    "#prediction with rf\n",
    "predRF = rf.predict(testX) \n",
    "\n",
    "# error of random forest\n",
    "rfDiff = np.abs(predRF - testY)\n",
    "rf_avgErr = np.mean(rfDiff)\n",
    "rf_stdErr = np.std(rfDiff)\n",
    "\n",
    "print(\"Score RF:\", rf_score)\n",
    "print(\"Avg Error RF:\", rf_avgErr)\n",
    "print(\"Std Error RF:\", rf_stdErr)\n",
    "\n",
    "#confusion matrix\n",
    "print(\"RF Learn Confusion Matrix:\")\n",
    "print(confusion_matrix(testY,predRF))\n",
    "print(\"accuracy:\",accuracy_score(testY,predRF))\n",
    "print(\"precision:\",precision_score(testY,predRF))\n",
    "print(\"recall:\",recall_score(testY,predRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score GD: 0.8143607705779334\n",
      "Avg Error GD: 0.18563922942206654\n",
      "Std Error GD: 0.388815259373456\n",
      "GD Learn Confusion Matrix:\n",
      "[[367  41]\n",
      " [ 65  98]]\n",
      "accuracy: 0.8143607705779334\n",
      "precision: 0.7050359712230215\n",
      "recall: 0.6012269938650306\n"
     ]
    }
   ],
   "source": [
    "#gradient descent method\n",
    "\n",
    "theta = [0,0,0,0,0,0] #initial model parameters\n",
    "alpha = 0.1 # learning rates\n",
    "max_iteration = 1000 # maximal iterations\n",
    "\n",
    "m = len(y) # number of samples\n",
    "\n",
    "for x in range(max_iteration):\n",
    "        # call the functions for gradient descent method\n",
    "        new_theta = Gradient_Descent(X,y,theta,m,alpha)\n",
    "        theta = new_theta\n",
    "        if x % 200 == 0:\n",
    "            # calculate the cost function with the present theta\n",
    "            Cost_Function(X,y,theta,m)\n",
    "            \n",
    "#get score for gradient descent method \n",
    "score = 0\n",
    "length = len(testX)\n",
    "for i in range(length):\n",
    "        prediction = round(Prediction(theta,testX[i]))\n",
    "        answer = testY[i]\n",
    "        if prediction == answer:\n",
    "            score += 1\n",
    "\n",
    "GD_score = float(score) / float(length)\n",
    "            \n",
    "#prediction with gradient descent method\n",
    "predGD = [Prediction(theta,i) for i in testX]\n",
    "predGD = [float(int(j>=.6)) for j in predGD]\n",
    "\n",
    "#evaluation\n",
    "testDiff = np.abs(predGD - testY)\n",
    "avgErr = np.mean(testDiff)\n",
    "stdErr = np.std(testDiff)\n",
    "\n",
    "print(\"Score GD:\", GD_score)\n",
    "print(\"Avg Error GD:\", avgErr)\n",
    "print(\"Std Error GD:\", stdErr)\n",
    "\n",
    "#confusion matrix\n",
    "print(\"GD Learn Confusion Matrix:\")\n",
    "print(confusion_matrix(testY,predGD))\n",
    "print(\"accuracy:\",accuracy_score(testY,predGD))\n",
    "print(\"precision:\",precision_score(testY,predGD))\n",
    "print(\"recall:\",recall_score(testY,predGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF method won!\n",
      "SK score: 0.8651488616462347\n",
      "SVM score: 0.8633975481611208\n",
      "RF score: 0.9824868651488616\n",
      "GD score: 0.8143607705779334\n"
     ]
    }
   ],
   "source": [
    "# comparing different Methods\n",
    "SK_score = clf.score(testX,testY)\n",
    "SVM_score = svm.score(testX,testY)\n",
    "RF_score = rf.score(testX,testY)\n",
    "GD_score = float(score) / float(length)\n",
    "\n",
    "if (SVM_score > RF_score) & (SVM_score > SK_score) & (SVM_score > GD_score):\n",
    "    print ('SVM method won!') \n",
    "if (SK_score > RF_score) & (SK_score > SVM_score) & (SK_score > GD_score): \n",
    "    print ('SK method won!') \n",
    "if (RF_score > SK_score) & (RF_score > SVM_score) & (RF_score > GD_score): \n",
    "    print ('RF method won!')\n",
    "if (GD_score > SK_score) & (GD_score > SVM_score) & (GD_score > RF_score): \n",
    "    print ('GD method won!')\n",
    "print(\"SK score:\",SK_score)\n",
    "print(\"SVM score:\",SVM_score)\n",
    "print(\"RF score:\",RF_score)\n",
    "print(\"GD score:\",GD_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
